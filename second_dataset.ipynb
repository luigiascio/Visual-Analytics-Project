{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7580b7d",
   "metadata": {},
   "source": [
    "# SECOND DATASET EXTRAPOLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4459a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tracks_statistical():\n",
    "\n",
    "    try:\n",
    "        nodes = pd.read_csv(\"data/nodes.csv\")\n",
    "        links = pd.read_csv(\"data/links.csv\", low_memory=False) \n",
    "    except FileNotFoundError:\n",
    "        print(\"Errore: File csv non trovati.\")\n",
    "        return\n",
    "\n",
    "    # 1. Calcolo Statistiche della Flotta\n",
    "    print(\"Calcolo soglie statistiche (75° e 90° percentile) su tutta la flotta...\")\n",
    "    \n",
    "    fishing_vessels = nodes[nodes['type'] == 'Entity.Vessel.FishingVessel']['id'].tolist()\n",
    "    \n",
    "    all_pings = links[\n",
    "        (links['type'] == 'Event.TransportEvent.TransponderPing') & \n",
    "        (links['target'].isin(fishing_vessels))\n",
    "    ].copy()\n",
    "    \n",
    "    if 'dwell' in all_pings.columns:\n",
    "        all_pings['dwell'] = pd.to_numeric(all_pings['dwell'], errors='coerce').fillna(0)\n",
    "    else:\n",
    "        all_pings['dwell'] = 0\n",
    "\n",
    "    all_pings['loc_clean'] = all_pings['source'].astype(str).str.replace(\"City of \", \"\")\n",
    "    \n",
    "    # --- SOGLIA STATISTICA ---\n",
    "    stats_df = all_pings.groupby('loc_clean')['dwell'].quantile([0.75, 0.90]).unstack()\n",
    "    \n",
    "    # Convertiamo in due dizionari separati per accesso veloce\n",
    "    thresholds_90 = stats_df[0.90].to_dict() # Soglia Rossa (Violation)\n",
    "    thresholds_75 = stats_df[0.75].to_dict() # Soglia Arancione (Suspicious)\n",
    "\n",
    "    # 2. Estrazione SouthSeafood\n",
    "    vessels = nodes[nodes['type'] == 'Entity.Vessel.FishingVessel']\n",
    "    all_vessel_ids = vessels['id'].tolist()\n",
    "    id_to_name = dict(zip(vessels['id'], vessels['entity_name']))\n",
    "    id_to_company = dict(zip(vessels['id'], vessels['company']))\n",
    "\n",
    "    # Filtro pings\n",
    "    all_pings['time'] = pd.to_datetime(all_pings['time'], format='mixed')\n",
    "    all_pings = all_pings.sort_values(by=['target', 'time'])\n",
    "\n",
    "    # Liste Zone\n",
    "    restricted_zones = [\"Ghoti Preserve\", \"Nemo Reef\", \"Don Limpet Preserve\"]\n",
    "    buoy_zones = [\n",
    "        \"Nav 1\", \"Nav 2\", \"Nav 3\",\n",
    "        \"Nav A\", \"Nav B\", \"Nav C\", \"Nav D\", \"Nav E\",\n",
    "        \"Exit East\", \"Exit North\", \"Exit South\", \"Exit West\"\n",
    "    ]\n",
    "    fishing_zones = [\"Wrasse Beds\", \"Cod Table\", \"Tuna Shelf\"] # Corretto \"Tuna\"\n",
    "\n",
    "    suspicious_scores = []\n",
    "    TARGET_COMPANY = \"SouthSeafood Express Corp\"\n",
    "    \n",
    "    for vid in all_vessel_ids:\n",
    "        v_pings = all_pings[all_pings['target'] == vid]\n",
    "        if len(v_pings) == 0: continue\n",
    "        \n",
    "        score = 0\n",
    "        track_data = []\n",
    "        company = str(id_to_company.get(vid, \"Unknown\"))\n",
    "        is_target_company = (company == TARGET_COMPANY)\n",
    "        \n",
    "        recent_buoy_visit = False\n",
    "\n",
    "        for _, row in v_pings.iterrows():\n",
    "            loc = row['loc_clean']\n",
    "            dwell = row['dwell']\n",
    "            \n",
    "            thresh_extreme = thresholds_90.get(loc, 14400) \n",
    "            thresh_warning = thresholds_75.get(loc, 900)   \n",
    "            \n",
    "            pt_type = \"port\"\n",
    "            \n",
    "            # Definiamo i booleani statistici\n",
    "            is_extreme = dwell > thresh_extreme\n",
    "            is_warning = dwell > thresh_warning\n",
    "            \n",
    "            # Reset Boa\n",
    "            if loc not in restricted_zones and loc not in buoy_zones:\n",
    "                recent_buoy_visit = False\n",
    "\n",
    "            # LOGICA SEMAFORO BASATA SUI PERCENTILI\n",
    "            if loc in restricted_zones:\n",
    "                if is_extreme:\n",
    "                    pt_type = \"violation\"\n",
    "                    points = 100\n",
    "                    if recent_buoy_visit: points += 150\n",
    "                    score += points\n",
    "                elif is_warning: \n",
    "                    pt_type = \"suspicious\" \n",
    "                    score += 10\n",
    "                else:\n",
    "                    pt_type = \"transit\"\n",
    "                    \n",
    "            elif loc in buoy_zones:\n",
    "                if is_extreme:\n",
    "                    pt_type = \"suspicious\"\n",
    "                    score += 20\n",
    "                    recent_buoy_visit = True\n",
    "                else:\n",
    "                    pt_type = \"transit\" # BLU\n",
    "                    recent_buoy_visit = True\n",
    "            \n",
    "            elif loc in fishing_zones:\n",
    "                pt_type = \"transit\" # BLU\n",
    "            \n",
    "            track_data.append({\n",
    "                \"loc\": loc,\n",
    "                \"time\": row['time'].strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                \"timestamp\": int(row['time'].timestamp() * 1000),\n",
    "                \"type\": pt_type,\n",
    "                \"duration\": int(dwell),\n",
    "                \"x_offset\": random.randint(-5, 5), # Utile per la mappa jitter\n",
    "                \"y_offset\": random.randint(-5, 5)\n",
    "            })\n",
    "\n",
    "        # Salvataggio se rilevante\n",
    "        if is_target_company or score >= 0:\n",
    "            suspicious_scores.append({\n",
    "                \"id\": vid,\n",
    "                \"name\": id_to_name[vid],\n",
    "                \"company\": company,\n",
    "                \"score\": score,\n",
    "                \"is_target\": is_target_company,\n",
    "                \"track\": track_data\n",
    "            })\n",
    "\n",
    "    # Ordina e Salva\n",
    "    suspicious_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    output_tracks = {}\n",
    "    for s in suspicious_scores:\n",
    "        output_tracks[s['name']] = s['track']\n",
    "\n",
    "    output_dir = \"vast-challenge-project/public\"\n",
    "\n",
    "    with open(f\"{output_dir}/other_candidates.json\", \"w\") as f:\n",
    "        json.dump(output_tracks, f, indent=2)\n",
    "    \n",
    "    # estraiamo solo le navi target\n",
    "    ss_tracks = {k: v for k, v in output_tracks.items() if any(s['name'] == k and s['is_target'] for s in suspicious_scores)}\n",
    "    with open(f\"{output_dir}/south_seafood_pings.json\", \"w\") as f:\n",
    "        json.dump(ss_tracks, f, indent=2)\n",
    "        \n",
    "    print(f\"File salvati in {output_dir}/: other_candidates.json e south_seafood_pings.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_tracks_statistical()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
